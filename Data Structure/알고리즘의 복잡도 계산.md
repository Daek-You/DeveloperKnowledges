## 1. 프로그램의 성능 분석
- 주어진 문제를 해결할 수 있는가? 👉🏻 필수
- 사용자가 원하는대로 정확하게 해결하는가? 👉🏻 필수
- 주석, 문서와 같이 문서화가 잘 되어 있는가? 👉🏻 좋은 프로그래밍 습관
- 모듈화가 잘 되어 있는가? 👉🏻 좋은 프로그래밍 습관
- 가독성이 좋은가? 👉🏻 좋은 프로그래밍 습관
- **공간 복잡도가 효율적인가? 👉🏻 성능**
- **시간 복잡도가 효율적인가? 👉🏻 성능**  
<br>

프로그램의 성능을 알아보는 방법으로는 `성능 분석(Complexity theory)`과 `성능 측정(Benchmarking)`이 있다.  

### 성능 측정(Benchmarking)
- **실제로 프로그램을 실행시켜 실행 시간이 얼마나 걸리는지 재보는 방법**  
- 가장 확실한 방법  
- **그러나 실행시키는 환경과 컴퓨터의 사양에 따라 영향을 많이 받는 단점**이 존재   

### 성능 분석(Complexity Theory)
- **프로그램을 실제로 실행시키지 않고, 성능을 측정하는 방법**  
- 시뮬레이션이라고 알려져 있는 `모의 실험`**과 `복잡도(Complexity)`로 나눌 수 있다.
- **`복잡도`** 방식을 보통 많이 사용
- 복잡도는 메모리와 관련된 **`공간 복잡도`**, 실행 시간과 관련된 **`시간 복잡도`**가 있다.
- 오늘날엔 메모리 공간 크기가 커지고 값이 싸져서, **`시간 복잡도`**를 더 중요하게 본다.  
<br>

## 2. 시간 복잡도(Time Complexity)

$$\mathrm{실행에 \ 걸리는 \ 시간}(T_p) = \mathrm{컴파일 \ 시간} + \mathrm{실행 \ 시간} $$

- 컴파일 시간은 고정적이며, 한 번만 필요
- $T_p$는 컴파일러 옵션과 하드웨어 사양에 따라 변함
- $T_p$를 어떻게 계산하는가? 👉🏻 **`프로그램 단계 수`**를 이용!  

### 프로그램 단계 수(Program Step)
- **실행 환경에 무관한, 프로그램의 시간을 재는 문법적인 혹은 논리적인 단위**
- 프로그램 단계 수를 계산할 때, 코드가 몇 줄이 실행되는가 위주로 계산
- **`s/e(Steps/Execution)`** : 명령문에 대한 단계 수
- **`Frequency`** : 실행 횟수  
```cpp
Float sum(float list[], int n)
{
	float tempsum = 0;              // s/e(1), Frequency(1)
	int i;
	for (i = 0; i < n; i++)         // s/e(1), Frequency(n + 1)
		tempsum += list[i];         // s/e(1), Frequency(n)
	return tempsum;                 // s/e(1), Frequency(1)
}
```  
<br>

**`프로그램 단계 수`**는 각 코드 라인의 $s/e \ \times \ \mathrm{Frequency}$을 다 합한 것으로 구할 수 있다.  

$$ 1 \times 1 + 1 \times (n + 1) + 1 \times n + 1 \times 1 = 2n + 3 $$
- 그런데 만약 다른 알고리즘의 프로그램 단계 수가 $2n + 2$라면,
  해당 알고리즘이 위 알고리즘보다 낫다고 객관적으로 이야기할 수 있을까?
- 이에 대한 이야기를 하는 것이 바로, **`점근 표기법`**  
<br>

## 3. 점근 표기법
- 정확한 프로그램 단계 수를 계산하는 것은 쉽지 않고, 애초에 프로그램 단계 수의 정의 자체가 정확하지 않음
- $(100n + 10) \ vs \  (30n + 30)$ 에서 둘 중 뭐가 더 나은 성능을 보여주는 것인가?
- 이걸 명확히 하기 위한 방법이 바로 **`점근 표기법`**  

### 점근 표기 방법
- $T_p(n) = n^2 + 100n$ 이라고 가정해보자.
- $n$ 이 충분히 클 경우, 임의의 상수 $c_3$에 대해 $T_p(n) > c_3n$ 를 만족한다.
- $n$ 이 작을 경우에는 어떻게 하든 간에 시간 상으로는 별 차이가 없다.  

#### 하지만 n이 아주 큰 숫자라면?  
- $T_p(n) = n^2 + 100n > c_3n$ 을 만족하기 시작한 $n$ 부터는 $n^2$ 이 $n$ 보다는 실행 시간이 더 걸릴 것이라고 추측이 가능해짐
- 이러한 관점에서 보면 프로그램 단계 수의 디테일을 보기 보다는, **해당 프로그램이 어떠한 형태로 흘러갈 것인가**를 봐야 함
	- $n$ 이 커질 때마다 1차 함수로 증가하느냐, 2차 함수, 3차 함수로 증가하느냐…  
- 이러한 관점으로 보기 위해선, 다음과 같은 **점근 표기법**들에 대해 알아볼 필요가 있음  

<br>

### [점근 표기법] 빅오(Big-Oh)  
<br>

$$ f(n) = \mathrm{O(g(n))} $$  

<br>

어떤 함수의 프로그램 단계 수를 $f(n)$ 이라고 하고 다음 조건을 만족할 때, $f(n)$ 은 $g(n)$ 이라는 **훨씬 더 단순한 단계 수의 빅오 형태로 표현**된다.  

> 상수 $c$, $n_0$에 대해, $n_0 \leq n$을 만족하는 모든 n에 대해 $f(n) \leq cg(n)$ 을 만족한다.  

<br>

- 예를 들어 $f(n)=3n+2$ 라고 할 때, $n \geq 2$ 인 모든 n에 대해 $3n + 2 \leq 4n$ 을 만족한다.
- 따라서, $f(n) = 3n+2$ 는 $\mathrm{O}(n)$ 으로 표기 가능
	- $\mathrm{O}$의 정의에서 더 간단한 $g(n)$ 형태로 표시할 수 있다고 했으므로, $f(n) = 3n+2$ 가 $c \times g(n) =4 \times n$ 으로 단순화하여 표기된 것
	- 즉, $c = 4$ 이고, $g(n) = n$ 이므로, 빅 오의 정의에 따라 $f(n) = \mathrm{O(g(n))} = \mathrm{O(n)}$  

#### 빅오 표현법의 단점
- 빅오 표현법은 프로그램 단계 수 다항식을 복잡하게 표현해봐야, 결국은 **단순한 형태로 귀결**된다는 점을 표현한 것
- **커다란 흐름에만 귀결되기에**, **`나머지 상수항`** 혹은 **`제일 큰 항`**을 제외한 다른 항들은 크게 고려가 되지 않는다.
- 하지만 빅오 표현법은 **`상한선`**을 정해놓는 것이기 때문에 $g(n)$ 을 터무니없이 키워 버리면, 모두 맞게 되는 황당한 상황이 발생한다.  

    > 가령 $g(n)=n^2$ 이라고 하면 당연히 $3n+2 \leq 3n^2$ 을 만족하겠지만, 이것은 우리가 원하는 바와 멀어지게 된다.   

<br>

### [점근 표기법] 오메가(Omega)
<br>


$$ f(n) = \Omega(g(n)) $$  
<br>

> 상수 $c$, $n_0$ 에 대해, $n_0 \leq n$ 을 만족하는 모든 $n$ 에 대해 $f(n) \geq cg(n)$ 을 만족한다.   
> - 단, $g(n)$ 은 $f(n)$ 의 **`lower bound`**여야 한다는 조건이 존재  

<br>

- $f(n)=3n+2$ 라고 할 때, $n \geq 1$ 인 모든 $n$ 에 대해 $3n + 2 \geq 3n$ 을 만족한다.
- $f(n) = 3n+2$ 에서 $n$ 보다 크거나 같은 항들은 차례대로 $n, n^2, n^3, ...$ 등이 있다.
- 그 중에 가장 작은 첫 번째인 $n$ 이 $g(n)$ 이 된다.
- 따라서, $f(n) = 3n+2$ 는 $\Omega(n)$ 으로 표기할 수 있다. 
- 하지만 이 표기법은 **`하한선`**을 정해놓은 것이기 때문에 $g(n)$ 을 너무 낮춰버리면 빅오 때와 같은 문제가 발생  
<br>

### [점근 표기법] 세타(Theta)
<br>


$$ f(n) = \Theta(g(n)) $$  

<br>

> 상수 $c$, $n_0$ 에 대해, $n_0 \leq n$ 을 만족하는 모든 n에 대해 $c_1g(n) \leq f(n) \leq c_2g(n)$ 을 만족한다.  
> - 단, $g(n)$은 $f(n)$의 `lower bound`이면서 `upper bound`여야 함  
> - `upper bound`는 찾고자 하는 값을 처음 초과한 값을 의미  
> - 즉, 두 경계 지점 사이로 범위를 좁히기 위한 표기법  

<br>

- $f(n)=3n+2$ 라고 할 때, $n \geq 2$ 인 모든 $n$ 에 대해 $3n+2 \geq 3n$ 과  $3n + 2 \leq 4n$ 을 만족한다.  
- $f(n)$ 의 `lower bound`는 $n$, `upper bound`는 $n^2$ 으로 볼 수 있다.
- `lower bound`는 끝 값을 포함하고, `upper bound`는 끝 값을 포함하지 않으므로 $[n, \ n^2)$ 으로 표기가 가능하다.  
- 따라서, $[n, \ n^2)$ 중에 가능한 건 $n$ 이므로, $f(n) = 3n+2$ 는 $\Theta(n)$ 으로 표기할 수 있다.   
<br>

## 4. 결론

![시간 복잡도](https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fs0pox%2Fbtq6Mbphdwr%2Fs5K0D58hi5hiSrBuxmHHwk%2Fimg.png)  
<br>

점근 표기법들에서 볼 수 있었듯, 시간 복잡도는 프로그램 단계 수 다항식에서 `가장 최고차항`에 따라 결정된다.  

> $O(1)$  
- 상수항으로, 입력 데이터 크기에 상관없이 항상 일정한 시간이 걸리는 알고리즘  
- 데이터가 증가해도 성능에 영향을 거의 미치지 않는다.
<br>

> $O(log_2 \ n)$  
- 입력 데이터의 크기가 커질수록, 처리 시간이 로그만큼 짧아지는 알고리즘 
- 데이터가 10배가 되면, 처리 시간은 2배가 된다.
- 이진 탐색이 대표적이며, 재귀가 순기능으로 이루어지는 경우도 해당
<br>

> $O(n)$  
- 입력 데이터의 크기에 비례하여 처리 시간이 선형적으로 증가하는 알고리즘  
- 데이터가 10배가 되면, 처리 시간도 10배
- 선형 탐색 알고리즘(ex. 연결리스트 순회)가 대표적
<br>

> $O(n \ log_2  \ n)$  
- 데이터가 많아질수록, 처리 시간이 로그배만큼 더 늘어나는 알고리즘
- 데이터가 10배가 되면, 처리 시간은 약 20배
- 정렬 알고리즘인 병합 정렬, 퀵 정렬의 평균 시간 복잡도
<br>

> $O(n^2)$  
- 데이터가 많아질수록 처리 시간이 급수적으로 늘어나는 알고리즘
- 데이터가 10배가 되면, 처리 시간은 최대 100배
- 이중 루프가 대표적
- 단, m이 n보다 작을 때는 반드시 $O(nm)$ 으로 표시하는 것이 바람직
<br>

> $O(2^n)$
- 데이터 양이 많아질수록 처리 시간이 기하급수적으로 늘어나는 알고리즘
- ex) 피보나치 수열, 재귀의 역기능
