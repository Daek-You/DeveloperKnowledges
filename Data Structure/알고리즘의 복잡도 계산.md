> **목차**  
> 1. [프로그램의 성능 분석](#1-프로그램의-성능-분석)  
> 1.1 [성능 측정](#성능-측정benchmarking)  
> 1.2 [성능 분석](#성능-분석complexity-theory)  
> 2. [시간 복잡도](#2-시간-복잡도time-complexity)  
> 2.1 [프로그램 단계 수](#프로그램-단계-수program-step)  
> 3. [점근 표기법](#3-점근-표기법)  
> 3.1 [점근 표기법 종류](#점근-방법)  
> 4. [결론](#4-결론)  

<br>

# 1. 프로그램의 성능 분석
프로그램의 평가 기준은 다음과 같이 있다.
- 주어진 문제를 해결할 수 있는가? 👉🏻 필수
- 사용자가 원하는대로 정확하게 해결하는가? 👉🏻 필수
- 주석, 문서와 같이 문서화가 잘 되어 있는가? 👉🏻 좋은 프로그래밍 습관
- 모듈화가 잘 되어 있는가? 👉🏻 좋은 프로그래밍 습관
- 가독성이 좋은가? 👉🏻 좋은 프로그래밍 습관
- <u>공간 복잡도가 효율적인가?</u> 👉🏻 성능
- <u>시간 복잡도가 효율적인가?</u> 👉🏻 성능  

<br>

프로그램의 성능을 알아보는 방법으로는 `성능 분석(Complexity theory)`과 `성능 측정(Benchmarking)`이 있다.  

### 성능 측정(Benchmarking)
> 실제로 프로그램을 실행시켜 실행 시간이 얼마나 걸리는지 재보는 방법  


- 가장 확실한 방법
- <u>그러나 실행시키는 환경과 컴퓨터의 사양에 따라 영향을 많이 받는 단점</u>이 존재  

<br>

### 성능 분석(Complexity Theory)
> 프로그램을 실제로 실행시키지 않고, 성능을 측정하는 방법  

- 시뮬레이션이라고 알려져 있는 `모의 실험`과 `복잡도(Complexity)`로 나눌 수 있다.
- 복잡도 방식을 보통 많이 사용
- 복잡도는 메모리와 관련된 `공간 복잡도`, 실행 시간과 관련된 `시간 복잡도`가 있다.
- 오늘날엔 메모리 공간 크기가 커지고 값이 싸져서, `시간 복잡도`를 더 중요하게 본다.  

<br>

# 2. 시간 복잡도(Time Complexity)
> 실행에 걸리는 시간($T_p$) = 컴파일 시간 + `실행 시간`  

- 컴파일 시간은 고정적이며, 한 번만 필요
- $T_p$는 컴파일러 옵션과 하드웨어 사양에 따라 변함
- $T_p$를 어떻게 계산하는가? 👉🏻 `프로그램 단계 수`를 이용!  

### 프로그램 단계 수(Program Step)
> 프로그램을 실행시키는 환경에 무관하게, 프로그램의 시간을 재는 문법적인 혹은 논리적인 단위  

- 프로그램 단계 수를 계산할 때, 코드가 몇 줄이 실행되는가 위주로 계산
- `s/e(Steps/Execution)` : 명령문에 대한 단계 수
- `Frequency` : 실행 횟수  

```cpp
Float sum(float list[], int n)
{
		float tempsum = 0;              // s/e(1), Frequency(1)
		int i;
		for (i = 0; i < n; i++)         // s/e(1), Frequency(n + 1)
				tempsum += list[i];     // s/e(1), Frequency(n)
		return tempsum;                 // s/e(1), Frequency(1)
}
```  

- 시간 복잡도는 각 코드 라인의 $s/e \ \times \ \mathrm{Frequency}$을 다 합한 것으로 구할 수 있다.
$$ 1 \times 1 + 1 \times (n + 1) + 1 \times n + 1 \times 1 = 2n + 3 $$  

- 그런데 만약 다른 알고리즘의 프로그램 단계 수가 $2n + 2$라면, 해당 알고리즘이 위 알고리즘보다 낫다고 객관적으로 이야기할 수 있을까?
- 이에 대한 이야기를 하는 것이 바로, `**점근 표기법**`  

<br>

# 3. 점근 표기법
- 정확한 프로그램 단계 수를 계산하는 것은 쉽지 않고, 애초에 프로그램 단계 수의 정의 자체가 정확하지 않음
- `100n + 10` VS `30n + 30`는 둘 중 뭐가 더 나은가?
- 이걸 명확히 하기 위한 방법이 바로 **점근 표기법**  

## 점근 방법
- $T_p(n) = n^2 + 100n$ 이라고 가정해보자.
- n이 충분히 클 경우, 임의의 상수 $c_3$에 대해 $T_p(n) > c_3n$ 를 만족한다.
- n이 작을 경우에는 어떻게 하든 간에 시간 상으로는 별 차이가 없다.  

<br>

> 하지만 n이 아주 큰 숫자라면?  

- $T_p(n) = n^2 + 100n > c_3n$ 을 만족하기 시작한 n부터는 $n^2$이 $n$보다는 실행 시간이 더 걸릴 것이라고 추측이 가능해짐
- 이러한 관점에서 보면 프로그램 단계 수의 디테일을 보기 보다는, <u>해당 프로그램이 어떠한 형태로 흘러갈 것인가</u>를 봐야 함.
    > n이 커질 때마다 n의 1차 함수로 증가하느냐, 2차 함수, 3차 함수로 증가하느냐…  

- 이러한 관점으로 보기 위해선, 다음과 같은 점근 표기법들에 대해 알아볼 필요가 있음  

<br>

## Big-Oh ($\mathrm{O}$)

$$ f(n) = \mathrm{O(g(n))} $$  

<br>

어떤 함수의 프로그램 단계 수를 $f(n)$이라고 하고, 다음 조건을 만족할 때, $f(n)$은 $g(n)$이라는 훨씬 더 단순한 단계 수의 빅오 형태로 표현된다.  

> 상수 $c$, $n_0$에 대해, $n_0 \leq n$을 만족하는 모든 n에 대해 $f(n) \leq cg(n)$ 을 만족한다.  

<br>

예를 들어 $f(n)=3n+2$라고 할 때, $n \geq 2$인 모든 n에 대해 $3n + 2 \leq 4n$을 만족한다. 따라서, $f(n) = 3n+2 $는 $\mathrm{O}(n)$으로 표기할 수 있다.  

$\mathrm{O}$의 정의에서 더 간단한 $g(n)$ 형태로 표시할 수 있다고 했으므로, $f(n) = 3n+2$가 $c \times g(n) =4 \times n$으로 단순화하여 표기된 것이다.  

즉, $c = 4$이고, $g(n) = n$이므로, 빅 오의 정의에 따라 $f(n) = \mathrm{O(g(n))} = \mathrm{O(n)}$  

<br>

- 빅 오가 표현하는 바는 프로그램 단계 수 다항식을 복잡하게 표현해봐야, 결국은 **단순한 형태로 귀결**된다는 점이다.
- 결국에는 그 커다란 흐름에만 귀결된다는 점이므로 `나머지 상수항` 혹은 `제일 큰 항`을 제외한 다른 항들은 크게 고려가 되지 않는다.
- 하지만 이러한 빅오 표현법은 상한선을 정해놓는 것이기 때문에 $g(n)$을 터무니없이 키워 버리면, 모두 맞게 되는 황당한 상황이 발생한다.  

    > 가령 $g(n)=n^2$이라고 하면 당연히 $3n+2 \leq 3n^2$을 만족하겠지만, 이것은 우리가 원하는 바와 멀어지게 된다. 

    > 이러한 점을 보완하여 미세한 차이를 조정해주기 위해, $\Omega$와 $\Theta$ 표기법도 존재    

<br>

## Omega ($\Omega$)

$$ f(n) = \Omega(g(n)) $$  

<br>

> 상수 $c$, $n_0$에 대해, $n_0 \leq n$을 만족하는 모든 n에 대해 $f(n) \geq cg(n)$ 을 만족한다.  

- 단, $g(n)$은 $f(n)$의 `lower bound`여야 한다는 조건이 존재  

    > $f(n)=3n+2$라고 할 때, $n \geq 1$인 모든 n에 대해 $3n + 2 \geq 3n$을 만족한다. $f(n) = 3n+2$에서 $n$보다 크거나 같은 항들은 차례대로 $n, n^2, n^3, ...$등이 있다. 그 중에 가장 작은 첫 번째인 $n$이 $g(n)$이 된다. 따라서, $f(n) = 3n+2 $는 $\Omega(n)$으로 표기할 수 있다.  

- 하지만, 이 표기법은 하한선을 정해놓은 것이기 때문에 $g(n)$을 너무 낮춰버리면 빅오 때와 같은 문제가 발생  

<br>

## Theta ($\mathrm{\Theta}$)

$$ f(n) = \Theta(g(n)) $$  

<br>

> 상수 $c$, $n_0$에 대해, $n_0 \leq n$을 만족하는 모든 n에 대해 $c_1g(n) \leq f(n) \leq c_2g(n)$ 을 만족한다.  

- 단, $g(n)$은 $f(n)$의 `lower bound`이면서 `upper bound`여야 함
    - `upper bound`는 찾고자 하는 값을 처음 초과한 값을 의미
    - 즉, 두 경계 지점 사이로 범위를 좁히기 위한 표기법  

> $f(n)=3n+2$라고 할 때, $n \geq 2$인 모든 n에 대해 $3n+2 \geq 3n$과  $3n + 2 \leq 4n$을 만족한다. $f(n)$의 `lower bound`는 $n$, `upper bound`는 $n^2$으로 볼 수 있다. `lower bound`는 끝 값을 포함하고, `upper bound`는 끝 값을 포함하지 않으므로 $[n, \ n^2)$으로 표기가 가능하다. 따라서, $[n, \ n^2)$ 중에 가능한 건 $n$이므로, $f(n) = 3n+2 $는 $\Theta(n)$으로 표기할 수 있다.  

<br>

# 4. 결론
- 점근 표기법들에서 볼 수 있었듯, 시간 복잡도는 프로그램 단계 수 다항식에서 `가장 최고차항`에 따라 결정된다.  

![시간 복잡도](https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fs0pox%2Fbtq6Mbphdwr%2Fs5K0D58hi5hiSrBuxmHHwk%2Fimg.png)  

- $O(1)$ : 상수항으로, 입력 데이터 크기에 상관없이 항상 일정한 시간이 걸리는 알고리즘
    - 데이터가 증가해도 성능에 영향을 거의 미치지 않는다,
- $O(log_2 \ n)$ : 입력 데이터의 크기가 커질수록, 처리 시간이 로그만큼 짧아지는 알고리즘
    - ex) 데이터가 10배가 되면, 처리 시간은 2배가 된다.
    - 이진 탐색이 대표적이며, 재귀가 순기능으로 이루어지는 경우도 해당
- $O(n)$ : 입력 데이터의 크기에 비례하여 처리 시간이 선형적으로 증가하는 알고리즘
    - ex) 데이터가 10배가 되면, 처리 시간도 10배
    - 선형 탐색 알고리즘(ex. 연결리스트 순회)가 대표적
- $O(n \ log_2  \ n)$  :  데이터가 많아질수록, 처리 시간이 로그배만큼 더 늘어나는 알고리즘
    - ex) 데이터가 10배가 되면, 처리 시간은 약 20배
    - 정렬 알고리즘인 병합 정렬, 퀵 정렬의 평균 시간 복잡도
- $O(n^2)$  :  데이터가 많아질수록 처리 시간이 급수적으로 늘어나는 알고리즘
    - ex)  데이터가 10배가 되면, 처리 시간은 최대 100배
    - 이중 루프가 대표적
    - 단, m이 n보다 작을 때는 반드시 $O(nm)$으로 표시하는 것이 바람직
- $O(2^n)$  :  데이터 양이 많아질수록 처리 시간이 기하급수적으로 늘어나는 알고리즘
    - ex) 피보나치 수열, 재귀의 역기능
